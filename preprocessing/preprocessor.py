import pandas as pd
import numpy as np
import datetime
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler
from sklearn.ensemble import IsolationForest
from scipy.stats import zscore
from pandas.api.types import is_numeric_dtype

class DataPreprocessor:
    """
    L·ªõp th·ª±c hi·ªán l√†m s·∫°ch d·ªØ li·ªáu nh∆∞ ƒëi·ªÅn c√°c gi√° tr·ªã khuy·∫øt, chu·∫©n ho√° ƒë·ªãnh
    d·∫°ng ki·ªÉu d·ªØ li·ªáu, lo·∫°i b·ªè nhi·ªÖu v√† d·ªØ li·ªáu d∆∞ th·ª´a.
    """
    def __init__(self, df: pd.DataFrame, encoders: dict):
        """
        Kh·ªüi t·∫°o ƒë·ªëi t∆∞·ª£ng v·ªõi DataFrame v√† b·ªô m√£ h√≥a (cho LabelEncoder).

        Parameters
        ----------
        df : pandas.DataFrame
            B·ªô d·ªØ li·ªáu c·∫ßn ti·ªÅn x·ª≠ l√Ω.
        encoders : dict
            Dict ƒë·ªÉ l∆∞u tr·ªØ c√°c LabelEncoder ƒë√£ fit.
        """
        self.df = df
        self.encoders = encoders

    # ************************************************
    # 1. FILL DATE NA (Ph∆∞∆°ng ph√°p n·ªôi suy ng√†y th√°ng)
    # ************************************************
    def clean_date_column(self, column_name: str = 'Date') -> pd.DataFrame:
            """
            X·ª≠ l√Ω c·ªôt ng√†y th√°ng: Chuy·ªÉn ƒë·ªïi, n·ªôi suy, lo·∫°i b·ªè tr√πng l·∫∑p v√† s·∫Øp x·∫øp.
            ƒê·∫£m b·∫£o m·ªói ng√†y l√† duy nh·∫•t v√† x·∫øp theo th·ª© t·ª± tƒÉng d·∫ßn.
            """
            # 1. Chuy·ªÉn ƒë·ªïi sang ki·ªÉu datetime, √©p bu·ªôc l·ªói th√†nh NaT
            self.df[column_name] = pd.to_datetime(
                self.df[column_name],
                errors='coerce',
                format='%m/%d/%Y'
            )

            print(f"B·∫Øt ƒë·∫ßu n·ªôi suy c√°c gi√° tr·ªã b·ªã thi·∫øu trong c·ªôt '{column_name}'...")

            # 2. X·ª≠ l√Ω n·ªôi suy (gi·ªØ nguy√™n logic c·ªßa b·∫°n)
            date_ordinal = self.df[column_name].apply(
                lambda x: x.toordinal() if pd.notna(x) else np.nan
            )
            date_ordinal_filled = date_ordinal.interpolate(method='linear')
            date_ordinal_filled = date_ordinal_filled.round().astype('Int64')

            self.df[column_name] = date_ordinal_filled.apply(
                lambda x: datetime.date.fromordinal(x) if pd.notna(x) else pd.NaT
            )
            self.df[column_name] = pd.to_datetime(self.df[column_name])

            print(f"ƒê√£ n·ªôi suy c·ªôt '{column_name}'.")

            # 3. LO·∫†I B·ªé C√ÅC NG√ÄY TR√ôNG L·∫∂P (B∆Ø·ªöC B·ªî SUNG ƒê·ªÇ ƒê·∫¢M B·∫¢O T√çNH DUY NH·∫§T)
            initial_rows = len(self.df)
            self.df.drop_duplicates(subset=[column_name], keep='first', inplace=True)
            dropped_rows = initial_rows - len(self.df)

            if dropped_rows > 0:
                print(f"ƒê√£ lo·∫°i b·ªè {dropped_rows} h√†ng tr√πng l·∫∑p theo c·ªôt '{column_name}'.")

            # 4. S·∫Øp x·∫øp l·∫°i v√† ƒë·∫∑t l·∫°i ch·ªâ m·ª•c (nh∆∞ ban ƒë·∫ßu)
            self.df.sort_values(by=column_name, inplace=True)
            self.df.reset_index(drop=True, inplace=True)

            print(f"ƒê√£ s·∫Øp x·∫øp l·∫°i v√† reset index.")
            print(f"C·ªôt '{column_name}' ƒë√£ ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi sang ki·ªÉu: {self.df[column_name].dtype}")

            return self.df
    # ************************************************
    # 2. X·ª¨ L√ù C·ªòT NG√ÄY (Chu·∫©n h√≥a ƒë·ªãnh d·∫°ng)
    # ************************************************
    def process_datetime_column(self, col="Date"):
        """
        Chu·∫©n h√≥a c·ªôt ng√†y theo nhi·ªÅu ƒë·ªãnh d·∫°ng kh√°c nhau, t·ª± ph√°t hi·ªán d·∫°ng ng√†y,
        c·ªë g·∫Øng chuy·ªÉn v·ªÅ Timestamp ch√≠nh x√°c.

        Tham s·ªë
        -------
        col : str
            T√™n c·ªôt c·∫ßn x·ª≠ l√Ω.

        Tr·∫£ v·ªÅ
        -------
        DataFrame
            DataFrame sau khi chu·∫©n h√≥a c·ªôt ng√†y.
        """
        def _normalize(x):
            if pd.isna(x):
                return pd.NaT
            if isinstance(x, (pd.Timestamp, datetime.datetime, datetime.date)):
                return pd.to_datetime(x, errors="coerce")

            x = str(x).strip()
            dt = pd.to_datetime(x, errors="coerce", dayfirst=False)
            if pd.notna(dt):
                return dt

            dt = pd.to_datetime(x, errors="coerce", dayfirst=True)
            if pd.notna(dt):
                return dt

            x2 = x.replace(".", "/").replace("-", "/")
            parts = x2.split("/")

            if len(parts) == 3:
                try:
                    a, b, c = map(int, parts)
                    if c > 31: # Xem c l√† nƒÉm
                        if a <= 12 and b > 12: # Y M D
                            return pd.Timestamp(year=c, month=a, day=b)
                        if b <= 12 and a > 12: # Y D M (Tr∆∞·ªùng h·ª£p √≠t x·∫£y ra nh∆∞ng c√¢n nh·∫Øc)
                            return pd.Timestamp(year=c, month=b, day=a)
                        return pd.Timestamp(year=c, month=a, day=b) # Y M D
                    if a > 31: # Xem a l√† nƒÉm
                        return pd.Timestamp(year=a, month=b, day=c) # Y M D
                except:
                    pass
            return pd.NaT

        self.df[col] = self.df[col].apply(_normalize)
        return self.df

    # ************************************************
    # 3. XO√Å C·ªòT / H√ÄNG CH·∫§T L∆Ø·ª¢NG TH·∫§P
    # ************************************************
    def drop_low_valid_columns(self, threshold_ratio=2 / 3):
        """
        Xo√° c·ªôt ho·∫∑c h√†ng c√≥ t·ª∑ l·ªá gi√° tr·ªã h·ª£p l·ªá d∆∞·ªõi m·ªôt ng∆∞·ª°ng nh·∫•t ƒë·ªãnh.

        Tham s·ªë
        -------
        threshold_ratio : float
            Ng∆∞·ª°ng t·ª∑ l·ªá (0‚Äì1), m·∫∑c ƒë·ªãnh 2/3.

        Tr·∫£ v·ªÅ
        -------
        DataFrame
            D·ªØ li·ªáu sau khi lo·∫°i b·ªè c·ªôt/h√†ng ch·∫•t l∆∞·ª£ng th·∫•p.
        """
        total_rows = len(self.df)
        threshold = total_rows * threshold_ratio

        cols_to_drop = [col for col in self.df.columns if self.df[col].notna().sum() < threshold]
        if cols_to_drop:
            print(" C·ªôt b·ªã xo√°:")
            for col in cols_to_drop:
                print(" -", col)
            self.df.drop(columns=cols_to_drop, inplace=True)

        total_cols = self.df.shape[1]
        row_threshold = total_cols * threshold_ratio
        rows_to_drop = self.df.index[self.df.notna().sum(axis=1) < row_threshold]

        if len(rows_to_drop) > 0:
            print("\n H√†ng b·ªã xo√°:")
            for r in rows_to_drop:
                print(" - Index", r)
            self.df.drop(index=rows_to_drop, inplace=True)

        return self.df

    # ************************************************
    # 4. XO√Å TR√ôNG L·∫∂P
    # ************************************************
    def check_and_drop_duplicates(self):
        """
        Ki·ªÉm tra v√† xo√° c√°c h√†ng tr√πng l·∫∑p trong DataFrame.

        Tr·∫£ v·ªÅ
        -------
        DataFrame
            D·ªØ li·ªáu sau khi xo√° tr√πng l·∫∑p v√† reset index.
        """
        print("C√°c h√†ng tr√πng l·∫∑p:")
        duplicate_rows = self.df[self.df.duplicated(keep=False)]
        print(duplicate_rows)

        self.df = self.df.drop_duplicates().reset_index(drop=True)
        print("\nS·ªë h√†ng sau khi xo√° tr√πng:", len(self.df))
        return self.df

    # ************************************************
    # 5. ƒêI·ªÄN GI√Å TR·ªä THI·∫æU
    # ************************************************

    def fill_missing(self, strategy="median", custom_value=None, neighbors=None):
        """
        ƒêi·ªÅn gi√° tr·ªã thi·∫øu cho to√†n b·ªô DataFrame b·∫±ng nhi·ªÅu chi·∫øn l∆∞·ª£c:
        mean, median, mode, ffill, custom, interpolate.

        Tham s·ªë
        -------
        strategy : str
            Chi·∫øn l∆∞·ª£c ƒëi·ªÅn gi√° tr·ªã.
        custom_value : any
            Gi√° tr·ªã ƒëi·ªÅn th·ªß c√¥ng (n·∫øu d√πng strategy='custom').
        neighbors : int ho·∫∑c None
            Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng gi√° tr·ªã l√¢n c·∫≠n khi n·ªôi suy.

        Tr·∫£ v·ªÅ
        -------
        DataFrame
            D·ªØ li·ªáu sau khi ƒëi·ªÅn gi√° tr·ªã thi·∫øu.
        """
        for col in self.df.columns:
            if self.df[col].isnull().sum() == 0:
                continue

            try:
                if strategy == "mean":
                    self.df[col] = self.df[col].fillna(self.df[col].mean())
                elif strategy == "median":
                    self.df[col] = self.df[col].fillna(self.df[col].median())
                elif strategy == "mode":
                    self.df[col] = self.df[col].fillna(self.df[col].mode()[0])
                elif strategy == "ffill":
                    self.df[col] = self.df[col].fillna(method="ffill")
                elif strategy == "custom":
                    self.df[col] = self.df[col].fillna(custom_value)
                elif strategy == "interpolate":
                    if neighbors is None:
                        self.df[col] = self.df[col].interpolate(method='linear')
                    else:
                        self.df[col] = self.df[col].interpolate(
                            method='linear',
                            limit=neighbors,
                            limit_direction='both'
                        )
            except:
                self.df[col] = self.df[col].fillna(self.df[col].mode()[0])

        return self.df

    # ************************************************
    # 6. X·ª¨ L√ù ƒê·ªäNH D·∫†NG S·ªê
    # ************************************************
    def clean_decimal_format(self, date_col_name: str = 'Date') -> pd.DataFrame:
        """
        Ki·ªÉm tra c√°c c·ªôt c√≥ ki·ªÉu d·ªØ li·ªáu 'object' (ngo·∫°i tr·ª´ c·ªôt ng√†y th√°ng),
        thay th·∫ø d·∫•u ',' b·∫±ng d·∫•u '.' (n·∫øu c√≥) v√† chuy·ªÉn v·ªÅ ki·ªÉu float.

        Tham s·ªë:
            date_col_name (str): T√™n c·ªôt ng√†y th√°ng ƒë·ªÉ lo·∫°i tr·ª´ kh·ªèi qu√° tr√¨nh ki·ªÉm tra.

        Tr·∫£ v·ªÅ:
            pd.DataFrame: DataFrame sau khi l√†m s·∫°ch ƒë·ªãnh d·∫°ng s·ªë.
        """
        df_cleaned = self.df
        object_cols = df_cleaned.select_dtypes(include=['object']).columns.tolist()

        # Lo·∫°i b·ªè c·ªôt ng√†y th√°ng kh·ªèi danh s√°ch c·∫ßn ki·ªÉm tra
        if date_col_name in object_cols:
            object_cols.remove(date_col_name)

        cleaned_cols = []

        for col in object_cols:
            try:
                # L·∫•y c·ªôt d∆∞·ªõi d·∫°ng chu·ªói
                col_as_str = df_cleaned[col].astype(str)

                # Ch·ªâ thay th·∫ø v√† chuy·ªÉn ƒë·ªïi n·∫øu c·ªôt c√≥ ch·ª©a d·∫•u ph·∫©y
                if col_as_str.str.contains(',', regex=False).any():
                    print(f" ƒêang l√†m s·∫°ch ƒë·ªãnh d·∫°ng s·ªë cho c·ªôt '{col}'...")
                    # Thay th·∫ø d·∫•u ph·∫©y b·∫±ng d·∫•u ch·∫•m v√† chuy·ªÉn v·ªÅ float
                    df_cleaned[col] = (col_as_str
                                        .str.replace(',', '.', regex=False)
                                        .astype(float))
                    cleaned_cols.append(col)
                else:
                    # Th·ª≠ chuy·ªÉn ƒë·ªïi sang s·ªë cho t·∫•t c·∫£ c√°c c·ªôt object c√≤n l·∫°i
                    df_cleaned[col] = pd.to_numeric(col_as_str, errors='coerce')
                    # Ki·ªÉm tra n·∫øu ki·ªÉu d·ªØ li·ªáu ƒë√£ chuy·ªÉn th√†nh s·ªë th·ª±c (float) ho·∫∑c s·ªë nguy√™n (int)
                    if df_cleaned[col].dtype.kind in 'fi' and col not in cleaned_cols:
                        cleaned_cols.append(col)

            except Exception as e:
                print(f" L·ªói kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi c·ªôt '{col}' sang float: {e}")

        if cleaned_cols:
            print(f" ‚úî ƒê√£ chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng s·ªë/chu·ªói s·ªë cho {len(cleaned_cols)} c·ªôt: {', '.join(cleaned_cols)}")
        else:
            print(" ‚úî Kh√¥ng t√¨m th·∫•y c·ªôt ki·ªÉu 'object' n√†o c·∫ßn l√†m s·∫°ch ƒë·ªãnh d·∫°ng s·ªë (ngo√†i c·ªôt ng√†y).")

        self.df = df_cleaned
        return self.df
    # ************************************************
    # 7. X·ª¨ L√ç NGO·∫†I LAI
    # ************************************************
    @staticmethod
    def detect_outliers_iqr(series):
        """Ph√°t hi·ªán ngo·∫°i lai b·∫±ng ph∆∞∆°ng ph√°p IQR."""
        Q1, Q3 = series.quantile(0.25), series.quantile(0.75)
        IQR = Q3 - Q1
        return (series < Q1 - 1.5 * IQR) | (series > Q3 + 1.5 * IQR)

    @staticmethod
    def detect_outliers_zscore(series, threshold=3):
        """Ph√°t hi·ªán ngo·∫°i lai b·∫±ng Z-score."""
        # Ch·ªâ √°p d·ª•ng Z-score cho c√°c gi√° tr·ªã ƒë√£ ƒëi·ªÅn ƒë·∫ßy ƒë·ªß
        return abs(zscore(series.dropna())) > threshold

    def handle_outliers(self, method="iqr"):
        """
        X·ª≠ l√Ω ngo·∫°i lai b·∫±ng IQR, Z-score ho·∫∑c IsolationForest.
        Gi√° tr·ªã ngo·∫°i lai ƒë∆∞·ª£c thay b·∫±ng NaN r·ªìi ƒëi·ªÅn l·∫°i b·∫±ng median.

        Tham s·ªë
        -------
        method : str
            iqr, zscore ho·∫∑c isolation_forest.

        Tr·∫£ v·ªÅ
        -------
        DataFrame
            D·ªØ li·ªáu sau khi x·ª≠ l√Ω ngo·∫°i lai.
        """
        numeric_cols = self.df.select_dtypes(include=np.number).columns

        for col in numeric_cols:
            if self.df[col].isnull().all():
                continue # B·ªè qua c·ªôt r·ªóng

            mask = pd.Series(False, index=self.df.index)

            if method == "iqr":
                mask = DataPreprocessor.detect_outliers_iqr(self.df[col])
            elif method == "zscore":
                data_clean = self.df[col].dropna()
                if not data_clean.empty:
                    outlier_indices = data_clean.index[DataPreprocessor.detect_outliers_zscore(data_clean)]
                    mask[outlier_indices] = True
            elif method == "isolation_forest":
                data_clean = self.df[[col]].dropna()
                if not data_clean.empty:
                    iso = IsolationForest(contamination=0.01, random_state=42)
                    preds = iso.fit_predict(data_clean)
                    mask[data_clean.index[preds == -1]] = True
            else:
                raise ValueError("Ph∆∞∆°ng ph√°p x·ª≠ l√Ω ngo·∫°i lai kh√¥ng h·ª£p l·ªá!")

            self.df.loc[mask, col] = np.nan # Thay ngo·∫°i lai b·∫±ng NaN

        print(f" ƒê√£ thay th·∫ø ngo·∫°i lai b·∫±ng NaN ({method}).")

        # Sau khi thay b·∫±ng NaN, ƒëi·ªÅn l·∫°i b·∫±ng median
        print(" Ti·∫øn h√†nh ƒëi·ªÅn l·∫°i gi√° tr·ªã thi·∫øu b·∫±ng median...")
        self.fill_missing("median")
        return self.df

    # ************************************************
    # 8. CHUY·ªÇN KI·ªÇU M·ªòT C·ªòT
    # ************************************************
    def convert_dtype(self, column, dtype, errors='raise', format=None):
        """
        Chuy·ªÉn ki·ªÉu d·ªØ li·ªáu cho m·ªôt c·ªôt.

        Tham s·ªë
        -------
        column : str
            T√™n c·ªôt.
        dtype : str ho·∫∑c callable
            Ki·ªÉu ƒë√≠ch (int, float, str, bool, datetime, category).
        errors : str
            N·∫øu 'raise' s·∫Ω b√°o l·ªói, 'coerce' chuy·ªÉn l·ªói th√†nh NaN.
        format : str
            ƒê·ªãnh d·∫°ng ng√†y s·ª≠ d·ª•ng khi dtype='datetime'.

        Tr·∫£ v·ªÅ
        -------
        DataFrame
            D·ªØ li·ªáu sau chuy·ªÉn ki·ªÉu.
        """
        if column not in self.df.columns:
            print(f" C·ªôt '{column}' kh√¥ng t·ªìn t·∫°i.")
            return self.df

        if dtype in ["datetime", "date", "time"]:
            if pd.api.types.is_datetime64_any_dtype(self.df[column]):
                print(f" C·ªôt '{column}' ƒë√£ l√† datetime -> b·ªè qua.")
                return self.df

        print(f" Chuy·ªÉn ki·ªÉu '{column}' -> {dtype}")

        try:
            if callable(dtype):
                self.df[column] = self.df[column].apply(dtype)
            elif dtype in ["int", "integer"]:
                self.df[column] = self.df[column].astype(float).astype("Int64")
            elif dtype == "float":
                self.df[column] = self.df[column].astype(float)
            elif dtype == "str":
                self.df[column] = self.df[column].astype(str)
            elif dtype == "bool":
                self.df[column] = self.df[column].astype(bool)
            elif dtype in ["datetime", "date", "time"]:
                self.df[column] = pd.to_datetime(self.df[column], errors=errors, format=format)
            elif dtype == "category":
                self.df[column] = self.df[column].astype("category")

            print(" Th√†nh c√¥ng!")
        except Exception as e:
            print(f" L·ªói: {e}")
            if errors == "raise":
                raise e

        return self.df

    # ************************************************
    # 9. CHUY·ªÇN KI·ªÇU NHI·ªÄU C·ªòT
    # ************************************************
    def convert_dtypes_bulk(self, mapping, errors="raise"):
        """
        Chuy·ªÉn ki·ªÉu h√†ng lo·∫°t c·ªôt.

        Tham s·ªë
        -------
        mapping : dict ho·∫∑c (list, dtype)
            dict: {c·ªôt: ki·ªÉu}
            tuple: ([danh s√°ch c·ªôt], ki·ªÉu)
        errors : str
            ƒêi·ªÅu khi·ªÉn h√†nh vi khi l·ªói chuy·ªÉn ki·ªÉu.

        Tr·∫£ v·ªÅ
        -------
        DataFrame
            D·ªØ li·ªáu sau chuy·ªÉn ki·ªÉu.
        """
        if isinstance(mapping, dict):
            for col, dtype in mapping.items():
                self.convert_dtype(col, dtype, errors=errors)
        elif isinstance(mapping, (list, tuple)) and len(mapping) == 2:
            cols, dtype = mapping
            for col in cols:
                self.convert_dtype(col, dtype, errors=errors)
        else:
            print(" mapping ph·∫£i l√† dict ho·∫∑c (list_c·ªôt, dtype)")
        return self.df

    # ************************************************
    # 10. D·ª∞ ƒêO√ÅN KI·ªÇU D·ªÆ LI·ªÜU
    # ************************************************
    def detect_best_dtype(self, series: pd.Series):
        """
        D·ª± ƒëo√°n ki·ªÉu d·ªØ li·ªáu ph√π h·ª£p nh·∫•t cho m·ªôt c·ªôt.

        Tr·∫£ v·ªÅ
        -------
        str
            Ki·ªÉu d·ªØ li·ªáu ƒë∆∞·ª£c g·ª£i √Ω: int, float, bool, datetime, str, category.
        """
        s = series.dropna()

        if pd.api.types.is_datetime64_any_dtype(s):
            return "datetime"

        if pd.api.types.is_numeric_dtype(s):
            return "int" if (s % 1 == 0).all() else "float"

        if s.dtype == object or pd.api.types.is_string_dtype(s):
            if s.astype(str).str.contains(r"[-/:\.]").mean() > 0.3:
                parsed = pd.to_datetime(s, errors="coerce", dayfirst=True)
                if parsed.notna().mean() > 0.8:
                    return "datetime"

            if s.astype(str).str.lower().isin(["true", "false", "0", "1"]).mean() == 1:
                return "bool"

        if s.nunique() / len(s) < 0.05:
            return "category"

        return "str"

    # ************************************************
    # 11. AUTO CONVERT
    # ************************************************
    def auto_convert(self):
        """
        T·ª± ƒë·ªông chuy·ªÉn ki·ªÉu d·ªØ li·ªáu h·ª£p l√Ω cho to√†n b·ªô DataFrame d·ª±a tr√™n detect_best_dtype().

        Tr·∫£ v·ªÅ
        -------
        DataFrame
            D·ªØ li·ªáu sau chuy·ªÉn ƒë·ªïi t·ª± ƒë·ªông.
        """
        print("\n B·∫ÆT ƒê·∫¶U T·ª∞ ƒê·ªòNG CHUY·ªÇN KI·ªÇU...\n")

        changed = []

        for col in self.df.columns:
            cur = str(self.df[col].dtype)
            best = self.detect_best_dtype(self.df[col])

            if cur.startswith("int") or cur == "Int64":
                current_logic = "int"
            elif cur.startswith("float"):
                current_logic = "float"
            elif "datetime" in cur:
                current_logic = "datetime"
            elif cur == "bool":
                current_logic = "bool"
            elif "category" in cur:
                current_logic = "category"
            else:
                current_logic = "str"

            if current_logic != best:
                print(f" {col}: {current_logic} -> {best}")
                self.convert_dtype(col, best, errors="coerce")
                changed.append((col, current_logic, best))
            else:
                print(f" {col} gi·ªØ nguy√™n ({current_logic})")

        print("\n HO√ÄN T·∫§T!")
        if changed:
            print("üîß C√°c c·ªôt ƒë√£ chuy·ªÉn ki·ªÉu:")
            for c, old, new in changed:
                print(f" - {c}: {old} -> {new}")
        else:
            print("‚úî Kh√¥ng c√≥ c·ªôt n√†o c·∫ßn chuy·ªÉn ki·ªÉu.")

        return self.df

    # ************************************************
    # 12. M√É H√ìA
    # ************************************************
    def label_encode(self, col):
        """
        M√£ h√≥a c·ªôt d·∫°ng chu·ªói th√†nh s·ªë b·∫±ng Label Encoding.

        Tr·∫£ v·ªÅ
        -------
        DataFrame
        """
        if col not in self.df.columns:
            print(f" C·ªôt '{col}' kh√¥ng t·ªìn t·∫°i.")
            return self.df

        le = LabelEncoder()
        # √âp v·ªÅ string ƒë·ªÉ LabelEncoder x·ª≠ l√Ω
        data_clean = self.df[col].astype(str).dropna()
        self.df[col].loc[data_clean.index] = le.fit_transform(data_clean)
        self.encoders[col] = le
        return self.df

    def onehot_encode(self, col):
        """
        M√£ h√≥a One-hot m·ªôt c·ªôt (t·∫°o nhi·ªÅu c·ªôt nh·ªã ph√¢n).

        Tr·∫£ v·ªÅ
        -------
        DataFrame
        """
        if col not in self.df.columns:
            print(f" C·ªôt '{col}' kh√¥ng t·ªìn t·∫°i.")
            return self.df

        ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')

        # Ch·ªâ l·∫•y c√°c gi√° tr·ªã kh√¥ng thi·∫øu ƒë·ªÉ fit v√† transform
        temp_df = self.df[[col]].astype(str) # ƒê·∫£m b·∫£o l√† chu·ªói
        arr = ohe.fit_transform(temp_df)

        new_cols = [f"{col}_{c}" for c in ohe.categories_[0]]

        # T·∫°o DataFrame m·ªõi cho c√°c c·ªôt One-Hot
        ohe_df = pd.DataFrame(arr, columns=new_cols, index=self.df.index)

        # N·ªëi l·∫°i
        self.df = pd.concat([self.df.drop(columns=[col]), ohe_df], axis=1)
        return self.df

    @staticmethod
    def text_to_number(text):
        """
        Chuy·ªÉn chu·ªói k√Ω t·ª± th√†nh s·ªë b·∫±ng c√°ch c·ªông m√£ ASCII t·ª´ng k√Ω t·ª±.
        """
        return sum(ord(c) for c in str(text))

    def apply_text_encoding(self, col):
        """
        M√£ h√≥a chu·ªói th√†nh s·ªë theo h√†m text_to_number().
        """
        if col not in self.df.columns:
            print(f" C·ªôt '{col}' kh√¥ng t·ªìn t·∫°i.")
            return self.df

        self.df[col] = self.df[col].apply(DataPreprocessor.text_to_number)
        return self.df
    
class DataScaler:
    """
    L·ªõp th·ª±c hi·ªán bi·∫øn ƒë·ªïi v√† chu·∫©n ho√° d·ªØ li·ªáu ƒë·ªÉ c√°c m√¥ h√¨nh h·ªçc m√°y ho·∫°t ƒë·ªông ·ªïn ƒë·ªãnh.
    """
    def __init__(self, df: pd.DataFrame, scalers: dict):
        """
        Kh·ªüi t·∫°o ƒë·ªëi t∆∞·ª£ng v·ªõi DataFrame v√† b·ªô scale (cho StandardScaler, MinMaxScaler).

        Parameters
        ----------
        df : pandas.DataFrame
            B·ªô d·ªØ li·ªáu c·∫ßn chu·∫©n h√≥a.
        scalers : dict
            Dict ƒë·ªÉ l∆∞u tr·ªØ c√°c Scaler ƒë√£ fit.
        """
        self.df = df
        self.scalers = scalers

    # ************************************************
    # 1. CHU·∫®N H√ìA D·ªÆ LI·ªÜU
    # ************************************************
    def scale(self, method="standard", columns=None):
        """
        Chu·∫©n ho√° d·ªØ li·ªáu s·ªë b·∫±ng StandardScaler, MinMaxScaler ho·∫∑c custom scaling.

        Tham s·ªë
        -------
        method : str
            Ki·ªÉu chu·∫©n h√≥a: standard, minmax, custom.
        columns : list, optional
            Danh s√°ch c√°c c·ªôt s·ªë c·∫ßn chu·∫©n h√≥a. N·∫øu None, s·∫Ω ch·ªçn t·∫•t c·∫£ c√°c c·ªôt s·ªë.

        Tr·∫£ v·ªÅ
        -------
        DataFrame
            D·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a.
        """
        if columns is None:
            numeric_cols = self.df.select_dtypes(include=np.number).columns
        else:
            numeric_cols = [col for col in columns if col in self.df.columns and is_numeric_dtype(self.df[col])]

        if numeric_cols.empty:
            print(" Kh√¥ng c√≥ c·ªôt s·ªë n√†o ƒë·ªÉ chu·∫©n h√≥a.")
            return self.df

        print(f" Chu·∫©n h√≥a b·∫±ng ph∆∞∆°ng ph√°p '{method}' cho c√°c c·ªôt: {list(numeric_cols)}")

        if method == "standard":
            scaler = StandardScaler()
            self.df[numeric_cols] = scaler.fit_transform(self.df[numeric_cols])
            self.scalers['standard'] = scaler
        elif method == "minmax":
            scaler = MinMaxScaler()
            self.df[numeric_cols] = scaler.fit_transform(self.df[numeric_cols])
            self.scalers['minmax'] = scaler
        elif method == "custom":
            for col in numeric_cols:
                min_val = self.df[col].min()
                max_val = self.df[col].max()
                if max_val - min_val == 0:
                    self.df[col] = 0 # Tr√°nh chia cho 0
                else:
                    self.df[col] = (self.df[col] - min_val) / (max_val - min_val)
        else:
            raise ValueError("Ph∆∞∆°ng ph√°p chu·∫©n h√≥a kh√¥ng h·ª£p l·ªá! (standard, minmax, custom)")

        return self.df

